{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHjIAUOGMLiI"
      },
      "source": [
        "# Welcome to assignment 1! üëèüëè\n",
        "\n",
        "The exercise's objectives are the following:\n",
        "\n",
        "1.   Understand the algorithms you learned in class.\n",
        "2.   Learn how to write code in Python and how to use Google Colab.\n",
        "3.   Have fun!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10dRH2qBks16"
      },
      "source": [
        "# Google Colab\n",
        "Colaboratory, or ‚ÄúColab‚Äù for short, is a product from Google Research. Colab allows anybody to write and execute arbitrary python code through the browser, and is especially well suited to AI, machine learning, data analysis and education. More technically, Colab is a hosted Jupyter notebook service that requires no setup to use, while providing free access to computing resources including GPUs.\n",
        "\n",
        "\n",
        "It is recommended to go through this [guide](https://www.datacamp.com/tutorial/tutorial-google-colab-for-data-scientists)\n",
        " before starting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUhq1ubdDE2v"
      },
      "source": [
        "**Important tip:** If the same variable name appears in two different cells, the variable value will be determined by the last cell to run, rather than by the position of the cell. Let's see an example,  run the three cells below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W36S7jvkENyg"
      },
      "outputs": [],
      "source": [
        "# cell 1\n",
        "x = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kei_W6-QEQD_"
      },
      "outputs": [],
      "source": [
        "# cell 2\n",
        "x = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPQkx5XQETF5",
        "outputId": "f05e57a4-86ad-4f9c-8ab0-b93332001db9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO3WdjItEVQh"
      },
      "source": [
        "now rerun cell 1 and print x again.\n",
        "\n",
        "The same applies to functions, classes, etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqyEJdJlivGi"
      },
      "source": [
        "To work with colab, save the assignment in a folder in Google Drive. Match the following two lines in the cell below with the location in which folder has been saved and run the cell.\n",
        "\n",
        "\n",
        "1.   !cp -r /content/drive/MyDrive/ \"**path to the folder**\" /* .\n",
        "2.   sys.path.append('/content/drive/MyDrive/ \"**path to folder**\" /FrozenKaleEnv.py')\n",
        "\n",
        "After running the cell below with the right path, you should see the contents of the assignment folder in the left-hand bar, under \"Files\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbeKpb1q3yiu",
        "outputId": "5c1794b2-0a2a-40b8-a8e4-1d72e518f0a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp -r /content/drive/MyDrive/Colab_Notebooks/236501_hw1/* . #line 1\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/236501_hw1/FrozenKaleEnv.py') # line 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daeBGgC4Oou-"
      },
      "source": [
        "# Getting started with Open AI gym\n",
        "\n",
        "[OpenAI Gym](http://gym.openai.com) is a toolkit for comparing AI and RL algorithms. It contains a wide variety of environments that you can train your agents on, and it is often used for benchmarking new methods in the AI research literature. \n",
        "There are also [leaderboards](https://github.com/openai/gym/wiki/Leaderboard) for different gym-environments, showing which methods have been most successful so far.\n",
        "\n",
        "In this assignments we will use OpenAI gym (within the course's scope).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik_YMt0HO_R9"
      },
      "source": [
        "# The Environment\n",
        "You will work on a custom version of the [Frozen Lake](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/) environment from OpenAI.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "1. Your goal is to find a route from the top left corner to the bottom right corner.\n",
        "2. Each position on the map is marked with a letter, and each letter has a different meaning:\n",
        "\n",
        "  *   S - Initial (start) position. There's only one initial state on the map and it's always at the upper left corner.\n",
        "  *   G - Final state. There's only one final state on the map and it's always in the lower right corner.\n",
        "  *   H - Hole. When your agent reachs a hole, it falls into the water and cannot continue walking.\n",
        "  *   P -  Portal. There are either two or zero portals on the map. When the agent reaches a portal, it is immediately transported to the other portal. You can assume that they will not appear in a final or initial state.\n",
        "  *   F -  Frozen lake. This is the most common square on the map. The agent can walk on it safely.\n",
        "\n",
        "  Your agent can move faster by collecting 3 special objects.\n",
        "\n",
        "  *   T - [Talaria](https://en.wikipedia.org/wiki/Talaria). A pair of Winged Sandals that help you fly to the square.\n",
        "  *   A - Air jorden. Jumping shoes that help you jump to the square.\n",
        "  *   L - Lightning. Makes you run faster to the square.\n",
        "\n",
        "  When the agent performs transition (s,a,s') and collects one of the objects (T,A,L) at state s', the collected object changes the cost of the transition (as detailed below). \n",
        "\n",
        "3. The cost of each transition (s,a,s') is based on the mark if the square s' you pass to:\n",
        "  * S - 1\n",
        "  * G - 1\n",
        "  * H - 0\n",
        "  * P - 100\n",
        "  * F - 10\n",
        "  * T - 3\n",
        "  * A - 2\n",
        "  * L - 1\n",
        "\n",
        "4. The pink square marks where your agent is.\n",
        "\n",
        "5. The number of states is equal to the number of squares on the map. The state index is calculated as follows: row_number *num_col + col_ number*. For example, the state index of the portal squere on row 3 is : 3 * 8 + 1 = 25.\n",
        "\n",
        "6. Our agent can perform 4 actions:\n",
        "  * 0 - Down\n",
        "  * 1 - Right\n",
        "  * 2 - Up\n",
        "  * 3 - Left\n",
        "  \n",
        "\n",
        "7. If the agent tries to move outside the board boundaries, he stays in the same place.\n",
        "\n",
        "8. Section 6 describes the order in which the nodes should be created.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XIvTBylGni-J"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "from gym import Env, logger, spaces, utils\n",
        "from gym.envs.toy_text.utils import categorical_sample\n",
        "from gym.error import DependencyNotInstalled\n",
        "\n",
        "from FrozenLakeEnv import FrozenLakeEnv\n",
        "from typing import List, Tuple\n",
        "import heapdict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iHTZ1L7bcMlw"
      },
      "outputs": [],
      "source": [
        "DOWN = 0\n",
        "RIGHT = 1\n",
        "UP = 2\n",
        "LEFT = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWEiS5mVn7mg"
      },
      "source": [
        "# Maps\n",
        "A map can be produced manually as shown in the cell below. We will only work on maps in which there is a route from the initial state to the final state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MaIE0Yqenp2O"
      },
      "outputs": [],
      "source": [
        "MAPS = {\n",
        "    \"4x4\": [\"SFFF\",\n",
        "            \"FHFH\",\n",
        "            \"FFFH\",\n",
        "            \"HFFG\"],\n",
        "    \"8x8\": [\n",
        "        \"SFFFFFFF\",\n",
        "        \"FFFFFTAL\",\n",
        "        \"TFFHFFTF\",\n",
        "        \"FPFFFHTF\",\n",
        "        \"FAFHFPFF\",\n",
        "        \"FHHFFFHF\",\n",
        "        \"FHTFHFTL\",\n",
        "        \"FLFHFFFG\",]\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIpo4KAgxE9q"
      },
      "source": [
        "\n",
        "# The Frozen Lake Environment ‚õ∑\n",
        "The file `FrozenLakeEnv.py` implements our own version of the frozen lake environment. It is recommended to go through the code. \n",
        "\n",
        "**Note: You are not allowed to change this file.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRBezhLKIIJH"
      },
      "source": [
        "Lets start by creating a new environment object.\n",
        "\n",
        "In order to create an environment object, you must provide it with a board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ce62lyU8L39",
        "outputId": "ad810ca4-8629-4326-94f1-2baaacc9d232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial state: 0\n"
          ]
        }
      ],
      "source": [
        "env = FrozenLakeEnv(MAPS[\"8x8\"])\n",
        "state = env.reset()\n",
        "print('Initial state:', state)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWYU-zl1J1_m"
      },
      "source": [
        "First, take a look at the state space $\\mathcal{S}$ (all possible states) and action space $\\mathcal{A}$ (all possible actions). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg7XAAByJ-IH",
        "outputId": "5d8bd80c-544d-4206-e5e7-4e6c5be92437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action Space Discrete(4)\n",
            "State Space Discrete(64)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Action Space {env.action_space}\")\n",
        "print(f\"State Space {env.observation_space}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqptD9FjiYni"
      },
      "source": [
        "***Remark***: You may have noticed that gym uses `observation_space` instead of state space. For the purpose of this homework, the state space is the same as the observations space. However, in some problems the full state cannot be observed, so the space of possible states may not be the same as the space of possible observations. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BASrtg6SHjFI"
      },
      "source": [
        "Now we will go throught some usfel methods (It is still recommended to go through the other methods in the class):\n",
        "\n",
        "`render()` - returns a printable view of the board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "kDNpfddaBWJk",
        "outputId": "0b735c8e-14ea-43e5-e047-978bdd1fe811"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cae74ae8d275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ],
      "source": [
        "env.set_state(30)\n",
        "print(env.render())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAaEmhts9vAT"
      },
      "source": [
        "The pink square represents the agent. The letter ◊¥*H*◊¥ represents holes, and the yellow square is the final state.\n",
        "\n",
        "Here are two more useful methods:\n",
        "\n",
        "`get_state()` - Returns the current state of the agent.\n",
        "\n",
        "`set_state(state)` - Sets the current state of the agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Z9On8M--ln",
        "outputId": "65f30ad2-367e-4273-e0e1-ed0f01a97da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mF\u001b[0m\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[43mG\u001b[0m\n",
            "\n",
            "the agent is at state: 18\n"
          ]
        }
      ],
      "source": [
        "env.set_state(18)\n",
        "print(env.render())\n",
        "print(f\"the agent is at state: {env.get_state()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VwmIbSyAcsC"
      },
      "source": [
        "`succ(state)` - Returns a dictionary that contains information on all the successors of a state.\n",
        "\n",
        "*   The keys are the actions.\n",
        "*   The values are tuples of the form (next state, cost, terminated). Note that terminated is true when the agent reaches a **final state** or a **hole**.\n",
        "\n",
        "\n",
        "\n",
        "***Tip***: You can loop through both keys and values by using the `items()` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ7l6kSnAxvt",
        "outputId": "300a3424-36aa-482a-fdc1-78fedfe3b7cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current state: 18\n",
            "\n",
            "*** Action: 0 ***\n",
            "Next state: 26\n",
            "Cost: 10.0\n",
            "Terminated: False\n",
            "\n",
            "*** Action: 1 ***\n",
            "Next state: 19\n",
            "Cost: 0.0\n",
            "Terminated: True\n",
            "\n",
            "*** Action: 2 ***\n",
            "Next state: 10\n",
            "Cost: 10.0\n",
            "Terminated: False\n",
            "\n",
            "*** Action: 3 ***\n",
            "Next state: 17\n",
            "Cost: 10.0\n",
            "Terminated: False\n",
            "\n"
          ]
        }
      ],
      "source": [
        "current_state = env.get_state()\n",
        "print(f\"Current state: {current_state}\\n\")\n",
        "for action, successor in env.succ(current_state).items():\n",
        "  print(f\"*** Action: {action} ***\")\n",
        "  print(f\"Next state: {successor[0]}\")\n",
        "  print(f\"Cost: {successor[1]}\")\n",
        "  print(f\"Terminated: {successor[2]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2qFBBDWBcVi"
      },
      "source": [
        "As you can see, the action 0 (down) will move your agent to state 26 and the transition will cost you 10. Action 1 will move your agent to state 19, which is a hole that will terminate your run.\n",
        "\n",
        "`is_final_state(state)` can assist you in distinguishing between a final state and a hole."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "7j097OzTBZ_4",
        "outputId": "87088084-5e54-40ed-9bb0-b0f7121305b3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'env' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4936/3940975988.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msucc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Next state: {state}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Cost: {cost}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Terminated: {terminated}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ],
      "source": [
        "state, cost, terminated = env.succ(current_state)[1]\n",
        "\n",
        "print(f\"Next state: {state}\")\n",
        "print(f\"Cost: {cost}\")\n",
        "print(f\"Terminated: {terminated}\")\n",
        "print(f\"Final state: {env.is_final_state(state)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptr9kbNole-Y"
      },
      "source": [
        "Let's see what happens when we apply succ(state) on a hole:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcpKGM5yli4M",
        "outputId": "3269417d-b76e-4439-e12d-4edcdc5142bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current state: 19\n",
            "\n",
            "*** Action: 0 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n",
            "*** Action: 1 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n",
            "*** Action: 2 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n",
            "*** Action: 3 ***\n",
            "Next state: None\n",
            "Cost: None\n",
            "Terminated: None\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Current state: 19\\n\")\n",
        "for action, successor in env.succ(19).items():\n",
        "  print(f\"*** Action: {action} ***\")\n",
        "  print(f\"Next state: {successor[0]}\")\n",
        "  print(f\"Cost: {successor[1]}\")\n",
        "  print(f\"Terminated: {successor[2]}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxny4BVOr-UT"
      },
      "source": [
        "As you can see, if the operator cannot be applied to the state, all returned values are \"None\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXDKjWAoCqW_"
      },
      "source": [
        "Now it's time to move your agent around ü§ñ.\n",
        "\n",
        "`step(action)` - will move your agent one step along the board.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLWj_oYaFM33",
        "outputId": "9bd1c46a-d9e3-4cf5-8720-8bb424bb1b61"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'env' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4936/2182148799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"New state:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cost:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Terminated:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ],
      "source": [
        "new_state, cost, terminated = env.step(DOWN)\n",
        "print(env.render())\n",
        "print(\"New state:\", new_state)\n",
        "print(\"cost:\", cost)\n",
        "print(\"Terminated:\", terminated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcHkCw8FipY"
      },
      "source": [
        "The step-function returns the following information:\n",
        "* __New state__: The state after the action is taken.\n",
        "* __Cost__: The immediate cost.\n",
        "* __Terminated__: Is the environment done? In our environment this will be false until the agent will reach a hole or a final state.\n",
        "\n",
        "Let's move your agent one step left towards the portal and see what happens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcEj7pZQFhdx",
        "outputId": "8dfa9c0d-31c4-46fa-a7f4-15b079e03e0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (Left)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mP\u001b[0m\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[43mG\u001b[0m\n",
            "\n",
            "New state: 37\n",
            "cost: 100\n",
            "Done: False\n"
          ]
        }
      ],
      "source": [
        "new_state, cost, done = env.step(LEFT)\n",
        "print(env.render())\n",
        "print(\"New state:\", new_state)\n",
        "print(\"cost:\", cost)\n",
        "print(\"Done:\", done)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XRITGRPGsfU"
      },
      "source": [
        "Have you noticed that your agent has moved to the second portalüò≤?\n",
        "\n",
        "On some maps, the portals can significantly shorten your route, but going through them is much more expensive, so it is not always advisable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh9NM7qDlxUc"
      },
      "source": [
        "Here are a few more useful attributes and methods:\n",
        "\n",
        "\n",
        "`env.nrow`, `env.ncol` - Row and columns number.\n",
        "\n",
        "`env.nA` - Number of actions.\n",
        "\n",
        "`env.nS` - Number of states.\n",
        "\n",
        "`env.lastaction` - The last action performed by the agent.\n",
        "\n",
        "`env.p1`, `env.p2` - This is the state number for each portal. If there are no portals on the board they are set to NULL.\n",
        "\n",
        "`env.inc(row, col, action)` - Given a position and an action, returns the new position.\n",
        "\n",
        "`env.to_row_col(state)` - Converts between state and location on the board.\n",
        "\n",
        "`env.to_state(row, col)` - Converts between location on the board and state.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoxs3sG0QyhF"
      },
      "source": [
        "We've finished our demo ü•≥ and it's time to reset the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfjMsGRnHoK0",
        "outputId": "af652635-ba45-400e-a2bb-d8bcf6460c1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "current state befor reset: 37\n",
            "current state after reset: 0\n"
          ]
        }
      ],
      "source": [
        "print(f\"current state befor reset: {env.get_state()}\")\n",
        "env.reset()\n",
        "print(f\"current state after reset: {env.get_state()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYqbtBE_kzDK"
      },
      "source": [
        "One (quite bad) strategy for out agent is to take a random action every time. Inside a gym-environment this can be done using `env.action_space.sample()`, which samples a random action from the action space. Look through the following loop and make sure that you understand what's going on. Here, we use `clear_output()` to clear the output of the Jupyter cell, and `time.sleep()` to pause between each action)\n",
        "\n",
        "\n",
        "Let's see what would happen if we try to brute-force our way to solving the problem.\n",
        "\n",
        "\n",
        "We'll create an infinite loop that runs until the agent reaches the final state.The `env.action_space.sample()` method automatically selects one random action from set of all possible actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZE__OgBx78N"
      },
      "outputs": [],
      "source": [
        "class RandomAgent():\n",
        "  def __init__(self):\n",
        "    self.env = None\n",
        "\n",
        "  def animation(self, epochs: int ,state: int, action: List[int], total_cost: int) -> None:\n",
        "      clear_output(wait=True)\n",
        "      print(self.env.render())\n",
        "      print(f\"Timestep: {epochs}\")\n",
        "      print(f\"State: {state}\")\n",
        "      print(f\"Action: {action}\")\n",
        "      print(f\"Total Cost: {total_cost}\")\n",
        "      time.sleep(1)\n",
        "\n",
        "  def random_search(self, FrozenLakeEnv: env) -> Tuple[List[int],int]:\n",
        "    self.env = env\n",
        "    self.env.reset()\n",
        "    epochs = 0\n",
        "    cost = 0\n",
        "    total_cost = 0\n",
        "\n",
        "    actions = []\n",
        "\n",
        "    state = self.env.get_initial_state()\n",
        "    while not self.env.is_final_state(state):\n",
        "      action = self.env.action_space.sample()\n",
        "      new_state, cost, terminated = self.env.step(action)\n",
        "        \n",
        "      while terminated is True and self.env.is_final_state(state) is False:\n",
        "        self.env.set_state(state)\n",
        "        action = self.env.action_space.sample()\n",
        "        new_state, cost, terminated = self.env.step(action)\n",
        "        \n",
        "      actions.append(action)\n",
        "      total_cost += cost\n",
        "      state = new_state\n",
        "      epochs += 1\n",
        "      \n",
        "      self.animation(epochs,state,action,total_cost)\n",
        "\n",
        "    return (actions, total_cost)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ9FDJWNZr3-"
      },
      "source": [
        "Let's check out this agent's performance!\n",
        "\n",
        "The output of this agent is the sequence of actions that led to the solution and the route's cost. \n",
        "\n",
        "Our random agent is not very successful, so we'll print his actions as they happen. \n",
        "\n",
        "1.   **Stop his run in the middle if you are tired of looking at him.**\n",
        "2.   After watching the agent please put the code in the box below in the a comment. During testing, we do not want the notebook to get stuck in this box.\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gc3-gJVZH3h"
      },
      "outputs": [],
      "source": [
        "#agent = RandomAgent()\n",
        "#agent.random_search(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW7YKLjCi4Qf"
      },
      "source": [
        "**Did you remember to put the code above in a comment?!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBKDB1Aja5JB"
      },
      "source": [
        "As you can see, a random policy is, unsurprisingly, not a good policy. However, what else can we do?\n",
        "\n",
        "This is where you come in!\n",
        "\n",
        "In this assignment you will be required to implement the following algorithms taught in class in order to solve the problem.\n",
        "\n",
        "Algorithms: \n",
        "1. BFS-G\n",
        "2. DFS-G\n",
        "3. ID-DFS-G\n",
        "4. Uniform Cost Search (UCS)\n",
        "5. Greedy Best Search\n",
        "6. W-A*\n",
        "7. A* epsilon\n",
        "\n",
        "Important to note!\n",
        "\n",
        "Each agent should return a tuple: (actions, cost, expended) \n",
        "*  actions - the list of integers containing the sequence of actions that produce your agent's solution (and not the entire search process).\n",
        "* cost -  an integer which holds the total cost of the solution.\n",
        "* expanded - an integer which holds the number of nodes that have been expanded during the search.\n",
        "\n",
        "The solution to our search problem is the path to the final state, not the final state itself (since it is known). By saving the actions, we are able to restore the path your agent found.\n",
        "\n",
        "\n",
        "Any other output, unless otherwise specified, will cause the running of the notebook to fail and will result in a grade of 0 !\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nikK0HKwhRw"
      },
      "source": [
        "\n",
        "Some Tips:\n",
        "1. Follow the pseudo-code shown in the lectures.\n",
        "2. You should write all your code within the classes. This way, we prevent overlapping functions with the same name while running the notebook.\n",
        "3. Consider implementing a \"node\" class.\n",
        "4. Using small boards will help you debug.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMwTzaJKw9gA"
      },
      "source": [
        "The function below (`print_solution()`) can be used for debugging purposes. It prints the sequence of actions it receives. The function will not be used to test your code, so you are welcome to change it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WQj77NFT0Wdc"
      },
      "outputs": [],
      "source": [
        "def print_solution(actions,env: FrozenLakeEnv) -> None:\n",
        "    env.reset()\n",
        "    total_cost = 0\n",
        "    print(env.render())\n",
        "    print(f\"Timestep: {1}\")\n",
        "    print(f\"State: {env.get_state()}\")\n",
        "    print(f\"Action: {None}\")\n",
        "    print(f\"Cost: {0}\")\n",
        "    time.sleep(1)\n",
        "\n",
        "    for i, action in enumerate(actions):\n",
        "      state, cost, terminated = env.step(action)\n",
        "      total_cost += cost\n",
        "      clear_output(wait=True)\n",
        "\n",
        "      print(env.render())\n",
        "      print(f\"Timestep: {i + 2}\")\n",
        "      print(f\"State: {state}\")\n",
        "      print(f\"Action: {action}\")\n",
        "      print(f\"Cost: {cost}\")\n",
        "      print(f\"Total cost: {total_cost}\")\n",
        "      \n",
        "      time.sleep(1)\n",
        "\n",
        "      if terminated is True:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGQKO6ka-5P"
      },
      "source": [
        "## 1. BFS-G\n",
        "**TO DO:** implement Breadth First Search (BFS) algorithm on graph like shown in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mvy3uyrQmvcv"
      },
      "outputs": [],
      "source": [
        "class node:\n",
        "  def __init__(self, state, parent, g = 0, h = 0):\n",
        "    self.state = state\n",
        "    self.parent = parent   \n",
        "    self.g = g\n",
        "    self.h = h "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dstm3kWhbCaE",
        "outputId": "eda1b987-0de7-48b9-b716-6fac601dca0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:43: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:43: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-21-4e6ff85f938e>:43: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  while len(OPEN) is not 0:\n"
          ]
        }
      ],
      "source": [
        "class BFSAgent:\n",
        "\n",
        "    def _init_(self):\n",
        "      self.env = None\n",
        "\n",
        "    def get_solution(self,solution_node: node, expanded: int, env : FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      total_cost = 0\n",
        "      actions = []\n",
        "      current_node = solution_node\n",
        "      parent_node = solution_node.parent\n",
        "      while(parent_node != None):\n",
        "        for action, successor in env.succ(current_node.parent.state).items():\n",
        "          if successor[0] == current_node.state:\n",
        "            actions.append(action) \n",
        "            total_cost += successor[1]\n",
        "\n",
        "        current_node = current_node.parent\n",
        "        parent_node = parent_node.parent \n",
        "        if parent_node.parent is None:\n",
        "          for action, successor in env.succ(parent_node.state).items():\n",
        "              if successor[0] == current_node.state:\n",
        "                  actions.append(action) \n",
        "                  total_cost += successor[1]\n",
        "          break\n",
        "        current_node_state = current_node.state\n",
        "        current_parent_state = parent_node.state\n",
        "      \n",
        "      actions.reverse()\n",
        "      return (actions, int(total_cost), expanded)\n",
        "    \n",
        "\n",
        "    def bfs_search(self, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      expanded = 0\n",
        "      OPEN = []\n",
        "\n",
        "      current_node = node(env.get_initial_state(), None)\n",
        "      if env.is_final_state(current_node.state):\n",
        "        return self.get_solution(current_node, expanded, env)\n",
        "      OPEN.append(current_node)\n",
        "      CLOSE = set()\n",
        "      while len(OPEN) is not 0:\n",
        "        current_node = OPEN.pop(0)\n",
        "        CLOSE.add(current_node.state)\n",
        "        expanded += 1\n",
        "        for action, successor in env.succ(current_node.state).items():\n",
        "          if successor[0] is None:\n",
        "            break\n",
        "\n",
        "          child = node(successor[0], current_node)\n",
        "\n",
        "          if child.state not in CLOSE and child.state not in [s.state for s in OPEN]:\n",
        "            if env.is_final_state(child.state):\n",
        "              return self.get_solution(child, expanded, env)\n",
        "            OPEN.append(child)\n",
        "      return self.get_solution(child, expanded, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfoBu-elP2To"
      },
      "source": [
        "Now lets test your BFS agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyTnlxozM-U6",
        "outputId": "81b097c3-1664-4740-a22b-172c3c7544a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total_cost: 164\n",
            "Expanded: 55\n",
            "Actions: [0, 0, 0, 1, 0, 0, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "BFS_agent = BFSAgent()\n",
        "actions, total_cost, expanded = BFS_agent.bfs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6cGuGv6nAqN",
        "outputId": "7e547fd8-e87a-4729-e54e-6af3ae665a89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (Right)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 10\n",
            "State: 63\n",
            "Action: 1\n",
            "Cost: 1.0\n",
            "Total cost: 164.0\n"
          ]
        }
      ],
      "source": [
        "print_solution(actions, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPab1LWaqmc4"
      },
      "source": [
        "## 2. DFS-G\n",
        "**TO DO:** implement Depth First Search (DFS) algorithm on graph like shown in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FmMvIQl_qnFU"
      },
      "outputs": [],
      "source": [
        "class DFSAgent:\n",
        "  \n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "      self.expanded = 0\n",
        "    \n",
        "    def get_solution(self,solution_node: node, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      total_cost = 0\n",
        "      actions = []\n",
        "      current_node = solution_node\n",
        "      parent_node = solution_node.parent\n",
        "\n",
        "      while(current_node.parent != None):\n",
        "        for action, successor in env.succ(current_node.parent.state).items():\n",
        "          if successor[0] == current_node.state:\n",
        "            actions.append(action) \n",
        "            total_cost += successor[1]\n",
        "\n",
        "        current_node = current_node.parent\n",
        "        parent_node = current_node.parent\n",
        "        if parent_node.parent is None: # if reached the initial state\n",
        "          for action, successor in env.succ(parent_node.state).items():\n",
        "              if successor[0] == current_node.state:\n",
        "                  actions.append(action) \n",
        "                  total_cost += successor[1]\n",
        "          break\n",
        "        \n",
        "      actions.reverse()\n",
        "      return (actions, int(total_cost), self.expanded)\n",
        "\n",
        "    def recursive_dfs(self, OPEN: List[node], CLOSE, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      current_node = OPEN.pop()\n",
        "      if env.is_final_state(current_node.state):\n",
        "        return self.get_solution(current_node,env)\n",
        "      CLOSE.add(current_node.state)\n",
        "      self.expanded += 1\n",
        "      for action, successor in env.succ(current_node.state).items():\n",
        "        if successor[0] is None:\n",
        "          CLOSE.add(current_node.state)\n",
        "          break\n",
        "\n",
        "        child = node(successor[0], current_node)\n",
        "        if child.state not in CLOSE and child.state not in [s.state for s in OPEN]:\n",
        "          OPEN.append(child)\n",
        "          result = self.recursive_dfs(OPEN, CLOSE, env)\n",
        "        else:\n",
        "          continue\n",
        "        if result != (None, 0, 0):\n",
        "            return result\n",
        "      return (None, 0, 0)\n",
        "\n",
        "\n",
        "    def dfs_search(self, env: FrozenLakeEnv)->Tuple[List[int], int, int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      OPEN = []\n",
        "      CLOSE = set()\n",
        "      \n",
        "      current_node = node(env.get_initial_state(), None)\n",
        "      OPEN.append(current_node)\n",
        "      return self.recursive_dfs(OPEN, CLOSE, env)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjAPRyCcQt82"
      },
      "source": [
        "Now lets test your DFS agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxvfljY8rYYX",
        "outputId": "194ee217-700c-4e7f-88e0-a8700496a09d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total_cost: 148\n",
            "Expanded: 20\n",
            "Actions: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "DFS_agent = DFSAgent()\n",
        "actions, total_cost, expanded = DFS_agent.dfs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t05mYuOkT_y",
        "outputId": "e27dbcc9-0bb2-4455-d044-7e52660a65d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (Right)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 10\n",
            "State: 63\n",
            "Action: 1\n",
            "Cost: 1.0\n",
            "Total cost: 164.0\n"
          ]
        }
      ],
      "source": [
        "print_solution(actions, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6o30STBteuO"
      },
      "source": [
        "## 3. ID-DFS-G\n",
        "**TO DO:** implement Iterative Deepening Depth First Search (ID-DFS) like shown in class. \n",
        "\n",
        "\n",
        "To find a solution, your agent needs to run the DFS-L-G (on graph) algorithm and go one step deeper with each iteration. You can assume that your code will not be interrupted in the middle of its execution. Thus, your agent should continue searching for a solution until a solution is found.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xasfBvXptf42",
        "outputId": "a0465e47-9e32-4694-f51c-52708dbd4259"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:51: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:51: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-26-c8816938b111>:51: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if result is not (None, 0, 0):\n"
          ]
        }
      ],
      "source": [
        "class IDDFSAgent:\n",
        "     \n",
        "    def __init__(self):\n",
        "      self.inv = None\n",
        "      self.expanded = 0\n",
        "\n",
        "    def get_solution(self,solution_node: node, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      total_cost = 0\n",
        "      actions = []\n",
        "      current_node = solution_node\n",
        "      parent_node = solution_node.parent\n",
        "\n",
        "      while(current_node.parent != None):\n",
        "        for action, successor in env.succ(current_node.parent.state).items():\n",
        "          if successor[0] == current_node.state:\n",
        "            actions.append(action) \n",
        "            total_cost += successor[1]\n",
        "\n",
        "        current_node = current_node.parent\n",
        "        parent_node = current_node.parent\n",
        "        if parent_node.parent is None: \n",
        "          for action, successor in env.succ(parent_node.state).items():\n",
        "              if successor[0] == current_node.state:\n",
        "                  actions.append(action) \n",
        "                  total_cost += successor[1]\n",
        "          break\n",
        "        \n",
        "      actions.reverse()\n",
        "      return (actions, int(total_cost), self.expanded)\n",
        "\n",
        "\n",
        "    def recursive_dfs_l(self, OPEN: List[node], CLOSE, l: int, env: FrozenLakeEnv) -> Tuple[List[int], int ,int]:\n",
        "      current_node = OPEN.pop()\n",
        "      if env.is_final_state(current_node.state):\n",
        "        return self.get_solution(current_node, env)\n",
        "      CLOSE.add(current_node.state)\n",
        "      if l == 0:\n",
        "        return (None, 0, 0)\n",
        "      self.expanded += 1\n",
        "      for action, successor in env.succ(current_node.state).items():\n",
        "        if successor[0] is None:\n",
        "          CLOSE.add(current_node.state)\n",
        "          break\n",
        "\n",
        "        child = node(successor[0], current_node)\n",
        "        if child.state not in CLOSE and child.state not in [s.state for s in OPEN]:\n",
        "          OPEN.append(child)\n",
        "          result = self.recursive_dfs_l(OPEN, CLOSE, l - 1, env)\n",
        "        else:\n",
        "          continue\n",
        "        if result is not (None, 0, 0):\n",
        "            return result\n",
        "      return (None, 0, 0)  \n",
        "\n",
        "\n",
        "    def dfs_l_search(self, env: FrozenLakeEnv, l: int) -> Tuple[List[int], int ,int]:\n",
        "      OPEN = []\n",
        "      CLOSE = set()\n",
        "      \n",
        "      current_node = node(env.get_initial_state(), None)\n",
        "      OPEN.append(current_node)\n",
        "      return self.recursive_dfs_l(OPEN, CLOSE, l, env)\n",
        "      \n",
        "\n",
        "    def id_dfs_search(self, env: FrozenLakeEnv) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      l = 0\n",
        "      while True:\n",
        "        result = self.dfs_l_search(env, l)\n",
        "        if result != (None, 0, 0):\n",
        "            return result\n",
        "        l += 1\n",
        "      return (None, 0, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTiDCJs7tzS-",
        "outputId": "0f4f3d50-2b34-4e3a-adb0-667cd9fa15ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total_cost: 155\n",
            "Expanded: 360\n",
            "Actions: [0, 0, 0, 1, 1, 1, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "ID_DFS_agent = IDDFSAgent()\n",
        "actions, total_cost, expanded = ID_DFS_agent.id_dfs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7wNtzJhTu9A",
        "outputId": "965770ce-46d0-4fa3-f484-1296a5640acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (Down)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mA\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[45m\u001b[45mG\u001b[0m\u001b[0m\n",
            "\n",
            "Timestep: 10\n",
            "State: 63\n",
            "Action: 0\n",
            "Cost: 1.0\n",
            "Total cost: 155.0\n"
          ]
        }
      ],
      "source": [
        "print_solution(actions, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIkPei1WKdKj"
      },
      "source": [
        "# Heapdict\n",
        "For the next algorithms, you will be required to maintain an \"open\" queue based on a certain value (g/h/v). To manage these queues efficiently and conveniently, please use [Heapdict](https://www.geeksforgeeks.org/priority-queue-using-queue-and-heapdict-module-in-python/). Heapdict implements the MutableMapping ABC, meaning it works pretty much like a regular Python [dictionary](https://www.geeksforgeeks.org/python-dictionary/). It‚Äôs designed to be used as a priority queue. Along with functions provided by ordinary dict(), it also has popitem() and peekitem() functions which return the pair with the lowest priority.\n",
        "\n",
        "Note:\n",
        "\n",
        "1.   When two nodes have the same minimum value, select the node with the lower state index first. Instead of defining priority as an integer, you can define it as a tuple (value, state).\n",
        "2.   To update a node in ◊¥open◊¥, please remove it from heapdict and re-insert it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l78oM31_xo60"
      },
      "source": [
        "## 4. Uniform Cost Search (UCS)\n",
        "TO DO: implement Uniform Cost Search (UCS) like shown in class.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6GxboQbVq3Z",
        "outputId": "04b6f00f-d752-48c0-e587-1af9919868a9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:45: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:45: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-29-35c8f2afaeda>:45: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  while len(OPEN) is not 0:\n"
          ]
        }
      ],
      "source": [
        "import heapdict\n",
        "class UCSAgent:\n",
        "    def __init__(self):\n",
        "        self.env = None\n",
        "     \n",
        "    def get_solution(self, solution_node: node, expanded: int, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      total_cost = 0\n",
        "      actions = []\n",
        "      current_node = solution_node\n",
        "      parent_node = solution_node.parent\n",
        "      current_node_state = solution_node.state\n",
        "      current_parent_state = parent_node.state\n",
        "      while(parent_node != None):\n",
        "        for action, successor in env.succ(current_parent_state).items():\n",
        "          if successor[0] == current_node_state:\n",
        "            actions.append(action) \n",
        "            total_cost += successor[1]\n",
        "\n",
        "        current_node = current_node.parent\n",
        "        parent_node = parent_node.parent \n",
        "        if parent_node.parent is None:\n",
        "          for action, successor in env.succ(parent_node.state).items():\n",
        "              if successor[0] == current_node.state:\n",
        "                  actions.append(action) \n",
        "                  total_cost += successor[1]\n",
        "          break\n",
        "        current_node_state = current_node.state\n",
        "        current_parent_state = parent_node.state\n",
        "      \n",
        "      actions.reverse()\n",
        "\n",
        "      \n",
        "      return (actions, int(total_cost), expanded)\n",
        "      \n",
        "\n",
        "\n",
        "    def ucs_search(self, env: FrozenLakeEnv) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      expanded = 0\n",
        "      OPEN = heapdict.heapdict()      \n",
        "      current_node = node(env.get_initial_state(), None,0)\n",
        "      OPEN[current_node] = (0,0)\n",
        "      CLOSE = set()\n",
        "      while len(OPEN) is not 0:\n",
        "        current_tuple = OPEN.popitem() # (node,(value,state index))\n",
        "        CLOSE.add(current_tuple[0].state) # add state to close\n",
        "        if env.is_final_state(current_tuple[0].state):\n",
        "          return self.get_solution(current_tuple[0],expanded,env)\n",
        "        expanded += 1\n",
        "        for action, successor in env.succ(current_tuple[0].state).items():\n",
        "          if successor[0] is None:\n",
        "            break\n",
        "          new_cost = current_tuple[0].g + successor[1]; # g + cost\n",
        "          child = node(successor[0], current_tuple[0], new_cost)\n",
        "\n",
        "          if child.state not in CLOSE and child.state not in [s.state for s in OPEN]:\n",
        "            OPEN[child] = (new_cost, successor[0])\n",
        "          elif child.state in [s.state for s in OPEN]:\n",
        "            for n in OPEN:\n",
        "              if n.state == child.state:\n",
        "                if n.g > child.g:\n",
        "                  OPEN.remove(n)\n",
        "                  OPEN[child] = (new_cost, successor[0])\n",
        "                break\n",
        "      return (None, 0, 0)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV-S9bFMmDmQ",
        "outputId": "8ffa8b8b-7a36-43fd-a59c-f1a0b2cd4eff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total_cost: 93\n",
            "Expanded: 56\n",
            "Actions: [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "UCS_agent = UCSAgent()\n",
        "actions, total_cost, expanded = UCS_agent.ucs_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIxWnmIAamYC"
      },
      "outputs": [],
      "source": [
        "print_solution(actions, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36V_9xlScMGG"
      },
      "source": [
        "## 5. Greedy Best First Search\n",
        "TO DO: implement Greedy Best First Search like shown in class.\n",
        "\n",
        "Note: The heurisitcs needed to be implemented. Instructions in dry pdf.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9UnBA8c3kx7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ZAQ_qjzPmiDN"
      },
      "outputs": [],
      "source": [
        "def man_heuristic(env: FrozenLakeEnv, state) -> int:\n",
        "    location = env.to_row_col(state)\n",
        "    sum = abs(env.ncol - location[1] - 1) + abs(env.nrow -1 - location[0])\n",
        "    return sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12oCdLcScqSZ",
        "outputId": "23e7b578-04d6-4a9f-ee7a-d879412b0c94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-38-acf6bfe49994>:41: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  while len(OPEN) is not 0:\n"
          ]
        }
      ],
      "source": [
        "class GreedyAgent:\n",
        "    def __init__(self):\n",
        "        self.env=None\n",
        "     \n",
        "    def get_solution(self, solution_node: node, expanded: int, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      total_cost = 0\n",
        "      actions = []\n",
        "      current_node = solution_node\n",
        "      parent_node = solution_node.parent\n",
        "      current_node_state = solution_node.state\n",
        "      current_parent_state = parent_node.state\n",
        "      while(parent_node != None):\n",
        "        for action, successor in env.succ(current_parent_state).items():\n",
        "          if successor[0] == current_node_state:\n",
        "            actions.append(action) \n",
        "            total_cost += successor[1]\n",
        "\n",
        "        current_node = current_node.parent\n",
        "        parent_node = parent_node.parent \n",
        "        if parent_node.parent is None:\n",
        "          for action, successor in env.succ(parent_node.state).items():\n",
        "              if successor[0] == current_node.state:\n",
        "                  actions.append(action) \n",
        "                  total_cost += successor[1]\n",
        "          break\n",
        "        current_node_state = current_node.state\n",
        "        current_parent_state = parent_node.state\n",
        "      \n",
        "      actions.reverse()\n",
        "      return (actions, int(total_cost), expanded)\n",
        "      \n",
        "\n",
        "    def Greedy_Best_First_search(self, env: FrozenLakeEnv) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      expanded = 0\n",
        "      OPEN = heapdict.heapdict()      \n",
        "      current_node = node(env.get_initial_state(), None, 0, min(man_heuristic(env,env.get_initial_state()), 100))\n",
        "      OPEN[current_node] = (min(man_heuristic(env, env.get_initial_state()), 100), 0)\n",
        "      CLOSE = set()\n",
        "      while len(OPEN) is not 0:\n",
        "        current_tuple = OPEN.popitem()##(node,(value,state index))\n",
        "        CLOSE.add(current_tuple[0].state) #add state to close\n",
        "        if env.is_final_state(current_tuple[0].state):\n",
        "          return self.get_solution(current_tuple[0],expanded,env)\n",
        "        expanded += 1\n",
        "        for action, successor in env.succ(current_tuple[0].state).items():\n",
        "          if successor[0] is None:\n",
        "            break\n",
        "\n",
        "          child = node(successor[0], current_tuple[0], 0, min(man_heuristic(env,successor[0]), 100))\n",
        "\n",
        "          if child.state not in CLOSE and child.state not in [s.state for s in OPEN]:\n",
        "            OPEN[child] = (child.h, successor[0]) \n",
        "      return (None, 0, 0)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZZmziDXp5Bo",
        "outputId": "e65eab3a-17d9-4671-eea1-f2f7243295e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total_cost: 113\n",
            "Expanded: 14\n",
            "Actions: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "Greedy_agent = GreedyAgent()\n",
        "actions, total_cost, expanded = Greedy_agent.Greedy_Best_First_search(env)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynUOuI6UqKiF"
      },
      "outputs": [],
      "source": [
        "print_solution(actions, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUnh0cwqrzfK"
      },
      "source": [
        "## 6. Weighted A*\n",
        "TO DO: implement Wighted A* like shown in class.\n",
        "\n",
        "Note:\n",
        "*   A parameter called `h_weight` is passed to `Greedy_Best_First_search()`, which indicates how much weight is given to the heuristics (ranging from 0 to 1).\n",
        "*   The heurisitcs needed to be implemented. Instructions in dry pdf.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slFZaOy9swBm",
        "outputId": "3b4e1bc6-bda8-4a17-ba08-20ef81c2ae69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:43: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:43: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-41-316765defa30>:43: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  while len(OPEN) is not 0:\n"
          ]
        }
      ],
      "source": [
        "class WeightedAStarAgent:\n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "     \n",
        "    def get_solution(self,solution_node: node, expanded: int, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      total_cost = 0\n",
        "      actions = []\n",
        "      current_node = solution_node\n",
        "      parent_node = solution_node.parent\n",
        "      current_node_state = solution_node.state\n",
        "      current_parent_state = parent_node.state\n",
        "      while(parent_node != None):\n",
        "        for action, successor in env.succ(current_parent_state).items():\n",
        "          if successor[0] == current_node_state:\n",
        "            actions.append(action) \n",
        "            total_cost += successor[1]\n",
        "\n",
        "        current_node = current_node.parent\n",
        "        parent_node = parent_node.parent \n",
        "        if parent_node.parent is None:\n",
        "          for action, successor in env.succ(parent_node.state).items():\n",
        "              if successor[0] == current_node.state:\n",
        "                  actions.append(action) \n",
        "                  total_cost += successor[1]\n",
        "          break\n",
        "        current_node_state = current_node.state\n",
        "        current_parent_state = parent_node.state\n",
        "      \n",
        "      actions.reverse()\n",
        "\n",
        "      \n",
        "      return (actions, int(total_cost), expanded)\n",
        "\n",
        "\n",
        "    def weighted_A_stare_search(self, env: FrozenLakeEnv, h_weight: float) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      expanded = 0\n",
        "      OPEN = heapdict.heapdict()\n",
        "      current_node = node(env.get_initial_state(), None, 0, min(man_heuristic(env, env.get_initial_state()), 100))\n",
        "      OPEN[current_node] = ((1 - h_weight) * current_node.g + h_weight * min(man_heuristic(env, env.get_initial_state()), 100), 0)\n",
        "      CLOSE = set()\n",
        "      while len(OPEN) is not 0:\n",
        "        current_tuple = OPEN.popitem()##(node,(value,state index))\n",
        "        CLOSE.add(current_tuple[0]) # add node to close\n",
        "        if env.is_final_state(current_tuple[0].state):\n",
        "          return self.get_solution(current_tuple[0], expanded, env)\n",
        "        expanded += 1\n",
        "\n",
        "        for action, successor in env.succ(current_tuple[0].state).items():\n",
        "          if successor[0] is None:\n",
        "            break\n",
        "          new_cost = current_tuple[0].g + successor[1]; # g + cost\n",
        "          child = node(successor[0], current_tuple[0], new_cost, min(man_heuristic(env, successor[0]), 100))\n",
        "          if child.state not in [s.state for s in CLOSE] and child.state not in [s.state for s in OPEN]:\n",
        "            OPEN[child] = ((1 - h_weight) * child.g + h_weight * child.h, successor[0])\n",
        "          elif child.state in [s.state for s in OPEN]:\n",
        "            for n in OPEN:\n",
        "              if n.state == child.state:\n",
        "                if ((1 - h_weight) * n.g + h_weight * n.h) > ((1 - h_weight) * child.g + h_weight * child.h):\n",
        "                  del OPEN[n]\n",
        "                  OPEN[child] = ((1 - h_weight) * child.g + h_weight * child.h, successor[0])\n",
        "                break\n",
        "          elif child.state in [s.state for s in CLOSE]:\n",
        "            for n in CLOSE:\n",
        "              if n.state == child.state:\n",
        "                if ((1 - h_weight) * n.g + h_weight * n.h) > (1 - h_weight) * child.g + h_weight * child.h:\n",
        "                  OPEN[child] = ((1 - h_weight) * child.g + h_weight * child.h, successor[0])\n",
        "                  CLOSE.remove(n)\n",
        "                break\n",
        "      return (None, 0, 0)\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xKSoHrMvJTG",
        "outputId": "ae049e0e-11bf-43d9-d7e2-0adb620875cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total_cost: 113\n",
            "Expanded: 14\n",
            "Actions: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "WA_agent = WeightedAStarAgent()\n",
        "actions, total_cost, expanded = WA_agent.weighted_A_stare_search(env,h_weight=1)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li9RGdElvetj"
      },
      "outputs": [],
      "source": [
        "print_solution(actions, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_nZTXgJxano"
      },
      "source": [
        "## 7. A*-epsilon:\n",
        "TO DO: implement A*-epsilon like shown in class.\n",
        "\n",
        "Note :\n",
        "*   A parameter called `epsilon` is passed to `A_star_epsilon_search()`.\n",
        "*   More Instructions in dry pdf.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaE7MW96xkHH",
        "outputId": "61031126-96e0-471f-9ff5-3a387e1a8f2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:57: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<>:57: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "<ipython-input-46-ce848304a92d>:57: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  while len(OPEN) is not 0:\n"
          ]
        }
      ],
      "source": [
        "class AStarEpsilonAgent:\n",
        "  \n",
        "    def __init__(self):\n",
        "      self.env = None\n",
        "     \n",
        "    def get_solution(self, solution_node: node, expanded: int, env: FrozenLakeEnv)-> Tuple[List[int], int, int]:\n",
        "      total_cost = 0\n",
        "      actions = []\n",
        "      current_node = solution_node\n",
        "      parent_node = solution_node.parent\n",
        "      current_node_state = solution_node.state\n",
        "      current_parent_state = parent_node.state\n",
        "      while(parent_node != None):\n",
        "        for action, successor in env.succ(current_parent_state).items():\n",
        "          if successor[0] == current_node_state:\n",
        "            actions.append(action) \n",
        "            total_cost += successor[1]\n",
        "\n",
        "        current_node = current_node.parent\n",
        "        parent_node = parent_node.parent \n",
        "        if parent_node.parent is None:\n",
        "          for action, successor in env.succ(parent_node.state).items():\n",
        "              if successor[0] == current_node.state:\n",
        "                  actions.append(action) \n",
        "                  total_cost += successor[1]\n",
        "          break\n",
        "        current_node_state = current_node.state\n",
        "        current_parent_state = parent_node.state\n",
        "      \n",
        "      actions.reverse()\n",
        "      return (actions, int(total_cost), expanded)\n",
        "\n",
        "    @staticmethod\n",
        "    def getMinNode(heap_dict) -> node:\n",
        "      min_focal_val = float(\"inf\")\n",
        "      min_node = None\n",
        "      for v in heap_dict:\n",
        "        if v.g <= min_focal_val:\n",
        "          if v.g == min_focal_val:\n",
        "            min_focal_val = v.g\n",
        "            if min_node.state > v.state:\n",
        "              min_node = v\n",
        "          else: \n",
        "            min_focal_val = v.g\n",
        "            min_node = v\n",
        "      return min_node\n",
        "\n",
        "\n",
        "    def A_star_epsilon_search(self, env: FrozenLakeEnv, epsilon: int) -> Tuple[List[int], int ,int]:\n",
        "      self.env = env\n",
        "      self.env.reset()\n",
        "      expanded = 0\n",
        "      OPEN = heapdict.heapdict()      \n",
        "      current_node = node(env.get_initial_state(), None, 0, min(man_heuristic(env, env.get_initial_state()), 100))\n",
        "      OPEN[current_node] = (current_node.g + current_node.h, 0)\n",
        "      CLOSE = set()\n",
        "      while len(OPEN) is not 0:\n",
        "        min_open = OPEN.peekitem()\n",
        "        FOCAL = [v for v in OPEN if (v.g + v.h) <= (1 + epsilon) * (min_open[1][0])]\n",
        "        min_node = self.getMinNode(FOCAL)\n",
        "        del OPEN[min_node]\n",
        "        CLOSE.add(min_node)\n",
        "        if env.is_final_state(min_node.state):\n",
        "          return self.get_solution(min_node, expanded, env)\n",
        "        expanded += 1\n",
        "        for action, successor in env.succ(min_node.state).items():\n",
        "          if successor[0] is None:\n",
        "            break \n",
        "          new_cost = min_node.g + successor[1]; # g + cost\n",
        "          child = node(successor[0], min_node, new_cost, min(man_heuristic(env, successor[0]), 100))\n",
        "          if child.state not in [s.state for s in CLOSE] and child.state not in [s.state for s in OPEN]:\n",
        "            OPEN[child] = (child.g + child.h,successor[0])\n",
        "          elif child.state in [s.state for s in OPEN]:\n",
        "            for n in OPEN:\n",
        "              if n.state == child.state:\n",
        "                if n.g > child.g:\n",
        "                  del OPEN[n]\n",
        "                  OPEN[child] = (child.g + child.h, successor[0])\n",
        "                break\n",
        "          elif child.state in [s.state for s in CLOSE]:\n",
        "             for n in CLOSE:\n",
        "               if n.state == child.state:\n",
        "                 if n.g > child.g:\n",
        "                   OPEN[child] = (child.g + child.h, successor[0])\n",
        "                   CLOSE.remove(n)\n",
        "                 break\n",
        "      return (None, 0, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z27oUmACSXNW",
        "outputId": "b11136e5-8dc7-42cb-c1de-f4aafa3ef4ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total_cost: 93\n",
            "Expanded: 56\n",
            "Actions: [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "A_star_epsilon_agent = AStarEpsilonAgent()\n",
        "actions, total_cost, expanded = A_star_epsilon_agent.A_star_epsilon_search(env,epsilon=1)\n",
        "print(f\"Total_cost: {total_cost}\")\n",
        "print(f\"Expanded: {expanded}\")\n",
        "print(f\"Actions: {actions}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "yBhTLtWP031Q",
        "outputId": "d1cbb745-042d-44d5-f306-f699474a5d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (Right)\n",
            "\u001b[43mS\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[45m\u001b[45mA\u001b[0m\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mA\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[42mP\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mT\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mT\u001b[0m\u001b[44mL\u001b[0m\n",
            "\u001b[44mF\u001b[0m\u001b[44mL\u001b[0m\u001b[44mF\u001b[0m\u001b[47mH\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[44mF\u001b[0m\u001b[43mG\u001b[0m\n",
            "\n",
            "Timestep: 8\n",
            "State: 14\n",
            "Action: 1\n",
            "Cost: 2.0\n",
            "Total cost: 55.0\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-df858008c11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-deb4c7b42998>\u001b[0m in \u001b[0;36mprint_solution\u001b[0;34m(actions, env)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total cost: {total_cost}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print_solution(actions, env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXDyMKvt81d5"
      },
      "source": [
        "# Submission:\n",
        "Your agents will be tested at the end of the notebook. \n",
        "\n",
        "In the cell below, you will be able to verify whether your agents can be called properly after running the entire notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yujJqR89oNu",
        "outputId": "81da240f-9bc1-4edb-cd06-743b79d54720"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***BFS Agent***\n",
            "env 8x8 : actions [0, 0, 0, 1, 0, 0, 0, 1, 1], Total_cost 164, Expanded 55\n",
            "env 4x4 : actions [0, 0, 1, 0, 1, 1], Total_cost 51, Expanded 14\n",
            "***DFS Agent***\n",
            "env 8x8 : actions [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 0, 1, 1], Total_cost 148, Expanded 20\n",
            "env 4x4 : actions [0, 0, 1, 0, 1, 1], Total_cost 51, Expanded 27\n",
            "***ID-DFS Agent***\n",
            "env 8x8 : actions [0, 0, 0, 1, 1, 1, 0, 0, 0], Total_cost 155, Expanded 360\n",
            "env 4x4 : actions [0, 0, 1, 0, 1, 1], Total_cost 51, Expanded 398\n",
            "***UCS Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0], Total_cost 93, Expanded 56\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51, Expanded 15\n",
            "***Greedy Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], Total_cost 113, Expanded 14\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51, Expanded 9\n",
            "***Weighted A* Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], Total_cost 113, Expanded 14\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51, Expanded 15\n",
            "***Epsilon A* Agent***\n",
            "env 8x8 : actions [1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0], Total_cost 93, Expanded 54\n",
            "env 4x4 : actions [1, 1, 0, 0, 0, 1], Total_cost 51, Expanded 15\n"
          ]
        }
      ],
      "source": [
        "env2 = FrozenLakeEnv(MAPS[\"4x4\"])\n",
        "BFS_agent = BFSAgent()\n",
        "actions, total_cost, expanded = BFS_agent.bfs_search(env)\n",
        "actions2, total_cost2, expanded2 = BFS_agent.bfs_search(env2)\n",
        "print(\"***BFS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "DFS_agent = DFSAgent()\n",
        "actions, total_cost, expanded = DFS_agent.dfs_search(env)\n",
        "actions2, total_cost2, expanded2 = DFS_agent.dfs_search(env2)\n",
        "print(\"***DFS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "ID_DFS_agent = IDDFSAgent()\n",
        "actions, total_cost, expanded = ID_DFS_agent.id_dfs_search(env)\n",
        "actions2, total_cost2, expanded2 = ID_DFS_agent.id_dfs_search(env2)\n",
        "print(\"***ID-DFS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "UCS_agent = UCSAgent()\n",
        "actions, total_cost, expanded = UCS_agent.ucs_search(env)\n",
        "actions2, total_cost2, expanded2 = UCS_agent.ucs_search(env2)\n",
        "print(\"***UCS Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "Greedy_agent = GreedyAgent()\n",
        "actions, total_cost, expanded = Greedy_agent.Greedy_Best_First_search(env)\n",
        "actions2, total_cost2, expanded2 = Greedy_agent.Greedy_Best_First_search(env2)\n",
        "print(\"***Greedy Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "WA_agent = WeightedAStarAgent()\n",
        "actions, total_cost, expanded = WA_agent.weighted_A_stare_search(env,h_weight=1)\n",
        "actions2, total_cost2, expanded2 = WA_agent.weighted_A_stare_search(env2,h_weight=0.5)\n",
        "print(\"***Weighted A* Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "###\n",
        "A_star_epsilon_agent = AStarEpsilonAgent()\n",
        "actions, total_cost, expanded = A_star_epsilon_agent.A_star_epsilon_search(env,epsilon=0)\n",
        "actions2, total_cost2, expanded2 = A_star_epsilon_agent.A_star_epsilon_search(env2,epsilon=100)\n",
        "print(\"***Epsilon A* Agent***\")\n",
        "print(f\"env 8x8 : actions {actions}, Total_cost {total_cost}, Expanded {expanded}\")\n",
        "print(f\"env 4x4 : actions {actions2}, Total_cost {total_cost2}, Expanded {expanded2}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b337601788dac84836857748c77dcd8b4a153d1d27944d244658cd27130a88f6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
